{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting individual run metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name != 'posix':\n",
    "        path = \"\\\\\\\\?\\\\\" + os.getcwd()\n",
    "        prefix = '\\\\'\n",
    "\n",
    "else:\n",
    "    path = os.getcwd()\n",
    "    prefix = '/'\n",
    "\n",
    "weights = files_classifier = os.listdir('Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot pre-training loss - for the individual layers\n",
    "1. load the hyperparameters file to know the number of epochs per layer\n",
    "2. use this number to slice the pre-training.csv loss file\n",
    "3. plot each slice - ie each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store hyperparameters\n",
    "hyperparameters = {}\n",
    "\n",
    "# Open and read the file\n",
    "with open(\"Hyperparameters.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        if \":\" in line:\n",
    "            # Split each line into key and value pairs\n",
    "            key, value = line.strip().split(\": \")\n",
    "            if key == \"epochs\":\n",
    "                epochs = int(value)\n",
    "\n",
    "            # Convert the value to the appropriate data type (e.g., int, float, list)\n",
    "            if key in [\"scaleaffine\", \"scale\", \"slope\", \"threshold\", \"bias\"]:\n",
    "                value = [float(x) for x in value.strip(\"[]\").split(\", \")]\n",
    "            elif key in [\"device\", \"nlayers\", \"nlayers_proj\", \"nneurons_proj\", \"epochs\", \"epochs_classifier\",\n",
    "                         \"batchSize_pretrain\", \"batchSize_classifier\", \"test_batchSize\"]:\n",
    "                value = int(value)\n",
    "            elif key in [\"lr\", \"lr_classifier\", \"deg\", \"contrast\", \"hue\"]:\n",
    "                value = float(value)\n",
    "            elif key in [\"dataset\"]:\n",
    "                value = value  # String values\n",
    "\n",
    "            # Store the key-value pair in the dictionary\n",
    "            hyperparameters[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data\n",
    "df_pretraining = pd.read_csv(\"pre_training.csv\", sep = ',', index_col = 0)\n",
    "len(df_pretraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping over the number of layer and try to extract the loss for that layer (ie chunks of len epochs)\n",
    "losses = []\n",
    "for layer in range(hyperparameters[\"nlayers\"]):\n",
    "    try:\n",
    "        losses.append(df_pretraining[\"Pre-training loss\"].values[layer*epochs: (layer+1)*epochs])\n",
    "    except:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.Reds\n",
    "\n",
    "colors = [colormap(i) for i in np.linspace(0.5,1,len(losses))]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for layer in range(len(losses)):\n",
    "    plt.plot(losses[layer], \"-\", color = colors[layer], label = \"Layer #\" + str(layer))\n",
    "\n",
    "plt.grid()\n",
    "plt.ylim([0, np.max(df_pretraining[\"Pre-training loss\"].values)])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Pre-training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training classifier for the different layers over epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_classifier = os.listdir('Classifiers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the filter function to categorize the files\n",
    "layers_files = [list(filter(lambda x: (int(x.split(\"#\")[1][0]) == layer), files_classifier)) for layer in range(hyperparameters[\"nlayers\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_files = [l for l in layers_files if l != [] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [l.sort(key=lambda x: int(x.split(\"#\")[2][:-4])) for l in layers_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(layers_files)+1,2, figsize = [10,10])\n",
    "train_e, test_e, train_l, test_l = [[] for k in range(len(layers_files))], [[] for k in range(len(layers_files))], [[] for k in range(len(layers_files))], [[] for k in range(len(layers_files))] \n",
    "\n",
    "for layer in range(len(layers_files)):\n",
    "    alphas = np.flip(np.linspace(1,0.2,len(layers_files[layer])))\n",
    "    try:\n",
    "        for epoch, file in enumerate(layers_files[layer]):\n",
    "            df_classifier = pd.read_csv(\"Classifiers/\"+ file, sep = ',', index_col = 0)\n",
    "            train_err, = axs[layer, 0].plot(df_classifier[\"Training error\"].values, color = \"firebrick\", alpha = alphas[epoch], label = \"Training error\")\n",
    "            train_e[layer].append(df_classifier[\"Training error\"].values[-1])\n",
    "            test_err, = axs[layer, 0].plot(df_classifier[\"Testing error\"].values, color = \"forestgreen\", alpha = alphas[epoch], label = \"Testing error\")\n",
    "            test_e[layer].append(df_classifier[\"Testing error\"].values[-1])\n",
    "            axs[layer, 0].set_ylim(0, np.max(df_classifier[\"Training error\"].values))\n",
    "            \n",
    "            train_loss, = axs[layer, 1].plot(df_classifier[\"Training loss\"].values, \"--\", color = \"firebrick\", alpha = alphas[epoch], label = \"Training loss\")\n",
    "            train_l[layer].append(df_classifier[\"Training loss\"].values[-1])\n",
    "            test_loss, = axs[layer, 1].plot(df_classifier[\"Testing loss\"].values, \"--\", color = \"forestgreen\", alpha = alphas[epoch], label = \"Testing loss\")\n",
    "            test_l[layer].append(df_classifier[\"Testing loss\"].values[-1])\n",
    "            axs[layer, 1].set_ylim(0, np.max(df_classifier[\"Training loss\"].values))\n",
    "        \n",
    "        axs[layer, 0].grid()\n",
    "        axs[layer, 0].set_xlabel(\"Epochs training classifier\")\n",
    "        axs[layer, 0].set_ylabel(\"Error (%)\")\n",
    "        \n",
    "        axs[layer, 0].legend([train_err, test_err], [\"Training error\", \"Testing error\"])\n",
    "        \n",
    "        axs[layer, 1].grid()\n",
    "        axs[layer, 1].set_xlabel(\"Epochs training classifier\")\n",
    "        axs[layer, 1].set_ylabel(\"Loss (CE)\")\n",
    "        axs[layer, 1].legend([train_err, test_err], [\"Training loss\", \"Testing loss\"])\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "alphas = np.flip(np.linspace(1,0.2,len(layers_files)))\n",
    "for layer in range(len(layers_files)):\n",
    "    train_err, = axs[-1, 0].plot(np.arange(0,50*len(train_e[layer]), 50), train_e[layer], color = \"firebrick\", alpha = alphas[layer], label = \"Training error\")\n",
    "    test_err, = axs[-1, 0].plot(np.arange(0,50*len(test_e[layer]), 50), test_e[layer], color = \"forestgreen\", alpha = alphas[layer], label = \"Testing error\")\n",
    "\n",
    "    train_loss, = axs[-1, 1].plot(np.arange(0,50*len(train_l[layer]), 50), train_l[layer], \"--\", color = \"firebrick\", alpha = alphas[layer], label = \"Training loss\")\n",
    "    test_loss, = axs[-1, 1].plot(np.arange(0,50*len(test_l[layer]), 50), test_l[layer], \"--\", color = \"forestgreen\", alpha = alphas[layer], label = \"Testing loss\")\n",
    "\n",
    "axs[-1, 0].set_ylim(0, np.max(df_classifier[\"Training error\"].values))\n",
    "axs[-1,0].set_xlabel(\"Pre-training epochs\")\n",
    "axs[-1,0].set_ylabel(\"Error (%)\")\n",
    "\n",
    "axs[-1, 1].set_ylim(0, np.max(df_classifier[\"Training loss\"].values))\n",
    "axs[-1,1].set_xlabel(\"Pre-training epochs\")\n",
    "axs[-1,1].set_ylabel(\"Loss (CE)\")\n",
    "\n",
    "\n",
    "axs[-1, 0].grid()\n",
    "axs[-1, 0].legend([train_err, test_err], [\"Training error\", \"Testing error\"])\n",
    "axs[-1, 1].grid()\n",
    "axs[-1, 1].legend([train_err, test_err], [\"Training loss\", \"Testing loss\"])   \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the last training curve for all the different layers (to see the difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = [10,10])\n",
    "alphas = np.flip(np.linspace(1,0.2,len(layers_files)))\n",
    "\n",
    "for layer in range(len(layers_files)):\n",
    "    try:\n",
    "        file = layers_files[layer][-1]\n",
    "        df_classifier = pd.read_csv(\"Classifiers/\"+ file, sep = ',', index_col = 0)\n",
    "        train_err, = axs[0].plot(df_classifier[\"Training error\"].values, color = \"firebrick\", alpha = alphas[layer], label = \"Training error\")\n",
    "        test_err, = axs[0].plot(df_classifier[\"Testing error\"].values, color = \"forestgreen\", alpha = alphas[layer], label = \"Testing error\")\n",
    "        axs[0].set_ylim(0, np.max(df_classifier[\"Training error\"].values))\n",
    "\n",
    "        train_loss, = axs[1].plot(df_classifier[\"Training loss\"].values, \"--\", color = \"firebrick\", alpha = alphas[layer], label = \"Training loss\")\n",
    "        test_loss, = axs[1].plot(df_classifier[\"Testing loss\"].values, \"--\", color = \"forestgreen\", alpha = alphas[layer], label = \"Testing loss\")\n",
    "        axs[1].set_ylim(0, np.max(df_classifier[\"Training loss\"].values))\n",
    "        \n",
    "       \n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "axs[0].grid()\n",
    "axs[0].legend([train_err, test_err], [\"Training error\", \"Testing error\"])\n",
    "\n",
    "axs[1].grid()\n",
    "axs[1].legend([train_err, test_err], [\"Training loss\", \"Testing loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot in an interactive way the weights of the first layer over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image, display, clear_output, IFrame\n",
    "from pdf2image import convert_from_path\n",
    "import io\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from the weights folder and sort by epochs\n",
    "files_weights = os.listdir('Weights')\n",
    "files_weights.sort(key=lambda x: int(x.split(\"#\")[1][:-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDF to images (one image per page)\n",
    "png_images = []\n",
    "for idx, file in enumerate(files_weights):\n",
    "    png_images.append(convert_from_path(\"Weights/\" + file)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pdf_image(image_idx):\n",
    "    clear_output(wait=False)\n",
    "    display(png_images[image_idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slider = widgets.IntSlider(\n",
    "    min=0,\n",
    "    max=len(files_weights) - 1,\n",
    "    step=1,\n",
    "    value=0,\n",
    "    description='Image:',\n",
    "    width='300px'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_display = widgets.interactive(display_pdf_image, image_idx=image_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_widget = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image_slider, output_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to update the displayed image\n",
    "def update_image(change):\n",
    "    with output_widget:\n",
    "        clear_output(wait=True)  # Clear the previous output\n",
    "        display(png_images[change.new].resize((600,600)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the slider to the update_image function\n",
    "image_slider.observe(update_image, 'value')\n",
    "\n",
    "# Display the initial image\n",
    "update_image({'new': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave('evolution_weights.gif', png_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
