{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data and target transfomations\n",
    "class ReshapeTransform:\n",
    "    def __init__(self, new_size):\n",
    "        self.new_size = new_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return torch.reshape(img, self.new_size)\n",
    "        \n",
    "        \n",
    "class ReshapeTransformTarget:\n",
    "    def __init__(self, number_classes):\n",
    "        self.number_classes = number_classes\n",
    "    \n",
    "    def __call__(self, target):\n",
    "        target=torch.tensor(target).unsqueeze(0).unsqueeze(1)\n",
    "        target_onehot = torch.zeros((1,self.number_classes))      \n",
    "        return target_onehot.scatter_(1, target, 1).squeeze(0)\n",
    "\n",
    "    \n",
    "class ContrastiveTransformations(object):\n",
    "    def __init__(self, base_transforms, n_views=2):\n",
    "        self.base_transforms = base_transforms #random transformations\n",
    "        self.n_views = n_views # number of differents copies with different \n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transforms(x) for i in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a MLP with Backprop first and try to fit the parameters of the VicREG objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataloader for the supervised training\n",
    "abatch_size = 256\n",
    "batch_size_test = 512\n",
    "\n",
    "transforms_supervised_train_data_aug =  transforms.Compose([torchvision.transforms.RandomRotation(degrees = 5, fill=0), #random rotation\n",
    "                                               torchvision.transforms.RandomCrop((28,28), padding = 2), #random crop\n",
    "                                               torchvision.transforms.RandomAffine(degrees=(0, 0), translate=(0.0, 0.0), scale=(0.9, 1.1)),\n",
    "                                               torchvision.transforms.ToTensor(),\n",
    "                                               ReshapeTransform((-1,))])\n",
    "    \n",
    "transforms_supervised_test = transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                       ReshapeTransform((-1,))])\n",
    "\n",
    "\n",
    "if data_aug:\n",
    "    train_loader_supervised = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(root='./data', train=True, download=True,\n",
    "                                transform = transforms_supervised_train_data_aug,\n",
    "                                target_transform=ReshapeTransformTarget(10)), batch_size = batch_size, shuffle=True)\n",
    "    \n",
    "else:\n",
    "    train_loader_supervised = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(root='./data', train=True, download=True,\n",
    "                                transform = transforms_supervised_test,\n",
    "                                target_transform=ReshapeTransformTarget(10)), batch_size = batch_size, shuffle=True)\n",
    "\n",
    "test_loader_supervised = torch.utils.data.DataLoader(\n",
    "torchvision.datasets.MNIST(root='./data', train=False, download=True,\n",
    "                            transform = transforms_supervised_test,\n",
    "                            target_transform=ReshapeTransformTarget(10)), batch_size = batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    ''' \n",
    "    Define the network used\n",
    "    '''\n",
    "    def __init__(self, run_gpu):\n",
    "\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.n_neurons = 1000\n",
    "        self.n_layers = 4\n",
    "        \n",
    "        self.layers = [nn.Linear(784, self.n_neurons, bias = False)]\n",
    "        self.layers += [nn.Linear(self.n_neurons, self.n_neurons, bias = False) for k in range(self.n_layers-1)]\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.classifier = nn.Linear(self.n_neurons, 10, bias = False)\n",
    "        \n",
    "        self.f = nn.ReLU()\n",
    "        \n",
    "        if run_gpu >= 0 and torch.cuda.is_available():\n",
    "            device = torch.device(run_gpu)\n",
    "            self.cuda = True\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            self.cuda = False\n",
    "\n",
    "        self.device = device\n",
    "        self = self.to(device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #simple forward pass of a MLP\n",
    "        \n",
    "        for idx, fc in enumerate(self.layers):\n",
    "            x = self.f(fc(x)) \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def forward_simple(self, x):\n",
    "        '''\n",
    "        Forward pass that stores the state of each layer during inference, discard the linear classifier\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            states = []\n",
    "            for idx, fc in enumerate(self.layers):\n",
    "                #1. compute forward pass for every layer\n",
    "                x = self.f(fc(x)) \n",
    "                states.append(x)\n",
    "\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader):\n",
    "    '''\n",
    "    Train the network for 1 epoch\n",
    "    '''\n",
    "    net.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    error, loss_tot = 0, 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        net.optimizer.zero_grad()\n",
    "        data, target  = data.to(net.device), target.to(net.device)\n",
    "       \n",
    "        y = net(data) \n",
    "        loss = criterion(y, torch.argmax(target, dim = 1))\n",
    "        loss.backward()\n",
    "        net.optimizer.step()\n",
    "        \n",
    "        loss_tot += loss.item()\n",
    "        del loss\n",
    "        error += (torch.argmax(y, dim =1) != torch.argmax(target, dim =1)).sum()\n",
    "\n",
    "    return net,(error/len(train_loader.dataset))*100, loss_tot/len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(net, test_loader):\n",
    "    '''\n",
    "    Train the network for 1 epoch\n",
    "    '''\n",
    "    net.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    error, loss_tot = 0, 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(test_loader)):\n",
    "        net.optimizer.zero_grad()\n",
    "        data, target  = data.to(net.device), target.to(net.device)\n",
    "        \n",
    "        y = net(data) \n",
    "        loss = criterion(y, torch.argmax(target, dim = 1))\n",
    "        loss_tot += loss.item()\n",
    "        del loss\n",
    "        \n",
    "        error += (torch.argmax(y, dim = 1) != torch.argmax(target, dim = 1)).sum()\n",
    "\n",
    "    return net,(error/len(test_loader.dataset))*100, loss_tot/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_aug:\n",
    "    n_epochs = 100\n",
    "else:\n",
    "    n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_error, test_error, train_loss, test_loss = [], [], [], []\n",
    "\n",
    "for k in range(n_epochs):\n",
    "    net, err, loss = train(net, train_loader_supervised)\n",
    "    train_error.append(err.item())\n",
    "    train_loss.append(loss)\n",
    "    \n",
    "    net, err, loss = test(net, test_loader_supervised)\n",
    "    test_error.append(err.item())\n",
    "    test_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_aug:\n",
    "    torch.save(net.state_dict(), \"Models/checkpoint_data_augmentations.pt\")\n",
    "else:\n",
    "    torch.save(net.state_dict(), \"Models/checkpoint.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NN_v2]",
   "language": "python",
   "name": "conda-env-NN_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
